[
  {
    "objectID": "tech-stack/index.html",
    "href": "tech-stack/index.html",
    "title": "tech stack",
    "section": "",
    "text": "I like keeping up with new tools and seeing what others are using. I’ve never seen a tech stack section of someone’s website, but maybe it’ll start a trend?",
    "crumbs": [
      "tech stack"
    ]
  },
  {
    "objectID": "teaching/courses/2025-spring-wvu-ieng-331/index.html",
    "href": "teaching/courses/2025-spring-wvu-ieng-331/index.html",
    "title": "WVU IENG 331",
    "section": "",
    "text": "This course introduces Industrial Engineering students to the practical application of Python for data analysis, process automation, and visualization, emphasizing real-world relevance and hands-on learning. Through projects and assignments, students will acquire skills to automate workflows, analyze datasets, and create effective data-driven solutions. The curriculum is designed to align with industry needs, fostering technical proficiency and communication skills for future challenges​."
  },
  {
    "objectID": "teaching/courses/2025-spring-wvu-ieng-331/index.html#course-description",
    "href": "teaching/courses/2025-spring-wvu-ieng-331/index.html#course-description",
    "title": "WVU IENG 331",
    "section": "",
    "text": "This course introduces Industrial Engineering students to the practical application of Python for data analysis, process automation, and visualization, emphasizing real-world relevance and hands-on learning. Through projects and assignments, students will acquire skills to automate workflows, analyze datasets, and create effective data-driven solutions. The curriculum is designed to align with industry needs, fostering technical proficiency and communication skills for future challenges​."
  },
  {
    "objectID": "teaching/courses/2025-spring-wvu-ieng-331/index.html#learning-objectives",
    "href": "teaching/courses/2025-spring-wvu-ieng-331/index.html#learning-objectives",
    "title": "WVU IENG 331",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nUpon successful completion of this course, students will be able to:\n\nImplement Python Programming Skills: Master the fundamentals of computer programming using Python, with a focus on industrial engineering applications.\nRecognize and Utilize Data Structures: Identify common data structures and their practical applications in solving engineering problems.\nAutomate Analytical Workflows: Develop, debug, and refine programs to automate data processing and analytical operations.\nLeverage Data Libraries: Apply specialized Python libraries for data cleaning, manipulation, visualization, and analysis, streamlining complex workflows.\nIntegrate with Databases: Connect to, query, design, and manage external datasets using relevant Python libraries.\nVisualize and Communicate Insights: Create effective data visualizations to communicate findings to technical and non-technical audiences, aligning with industry expectations.\nCollaborate and Utilize Version Control: Utilize Git and GitHub for collaboration, version control, and portfolio building, fostering professional software engineering practices.\nEngage with Real-World Data: Develop proficiency in handling diverse, real-world datasets through hands-on projects, preparing for industry or academic pursuits.\n\nThese objectives are designed to align with ABET-defined Student Outcomes, fostering critical skills in problem-solving, communication, teamwork, and lifelong learning. Additionally, they emphasize practical relevance, ensuring students are prepared for dynamic roles in industrial engineering and beyond."
  },
  {
    "objectID": "about-me/index.html",
    "href": "about-me/index.html",
    "title": "Ozan Ozbeker",
    "section": "",
    "text": "Hey again!\nA bit more about me: I’m especially interested in systems thinking, reproducible workflows, and making complex ideas understandable. I don’t believe in hyper-specializing. I admire the Renaissance polymaths like Da Vinci, and make it a goal to be able to contribute across the data stack. Whether that means building pipelines, developing forecasts, deploying web apps, or just making things a little less messy, I like to have my hands in all of it.\nI care deeply about open-source tools and transparent, reusable solutions.1 I try to reflect that mindset in the way I work, focusing on clarity, openness, and long-term maintainability rather than flashy dashboards or black-box outputs. I never realized how important good code & documentation is until I a couple trials by fire, and I don’t want to do that to anybody else.2\nThis year, I’ve been diving deep into Python as we shift away from R. (Don’t get me started.) Luckily, I made the move just as tools like Polars, uv, & marimo have hit their stride. It’s made the transition surprisingly smooth, especially compared to my college days of downloading 10 gigs of Anaconda bloatware. The {tidyverse} still holds a special place in my heart, and I would not be the analytical programmer I am without R for Data Science (2e).3 But I’m enjoying the Python ecosystem more broadly, especially beyond just analytics.\nI’m also realizing how much software engineering and industrial engineering overlap. At the end of the day, both are about optimizing your systems and continuous improvement. Building tools, web apps, and reports in a clean, Pythonic style scratches the same itch as designing physical systems. It feels like a natural evolution of the way I’ve always liked to work.\nOutside of work, I spend time at concerts, on bike rides, playing guitar, or buried in a side project that may or may not ever get finished. I also like learning skills related to my core work and adjacent. Lately, that’s been diving into self-hosting and homelabs.4\nIf any of this resonates, feel free to reach out!",
    "crumbs": [
      "about me"
    ]
  },
  {
    "objectID": "about-me/index.html#footnotes",
    "href": "about-me/index.html#footnotes",
    "title": "Ozan Ozbeker",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYes, I’m a professional Tableau hater.↩︎\nEspecially future me.↩︎\nIronically, I started learning R just as {tidyverse} 2.0 & R4DS 2e came out. I’m a pretty lucky guy apparently.↩︎\nAt some point I do want to build a MIDI-powered laser board, but baby steps.↩︎",
    "crumbs": [
      "about me"
    ]
  },
  {
    "objectID": "resume/index.html",
    "href": "resume/index.html",
    "title": "resume",
    "section": "",
    "text": "Results-driven Data Scientist with +4 years of experience delivering end-to-end data solutions that drive business impact and client success. Proven track record of transforming manual processes into scalable, automated systems while managing full data stack responsibilities from acquisition through deployment. Combines strong statistical foundation with modern data engineering practices to solve complex business problems. Recognized as a top 5% performer for technical excellence, client leadership, and strategic innovation. Experienced in client-facing roles with demonstrated ability to translate technical solutions into business value.\n\nData Science & Analytics: Statistical modeling, time series analysis, experimental design, predictive analytics, machine learning, forecasting, data visualization\nData Engineering: Pipeline design and optimization, ETL/ELT processes, data architecture, cloud platforms (GCS & AWS), modern data stack (Polars, DuckDB, Dagster), database management\nTechnical Leadership: Full-stack data solutions, process automation, performance optimization, technical mentoring, modernization of legacy systems, cross-functional collaboration\nClient Engagement: Stakeholder management, technical communication, requirements gathering, solution design, project leadership, business development",
    "crumbs": [
      "resume"
    ]
  },
  {
    "objectID": "resume/index.html#summary",
    "href": "resume/index.html#summary",
    "title": "resume",
    "section": "",
    "text": "Results-driven Data Scientist with +4 years of experience delivering end-to-end data solutions that drive business impact and client success. Proven track record of transforming manual processes into scalable, automated systems while managing full data stack responsibilities from acquisition through deployment. Combines strong statistical foundation with modern data engineering practices to solve complex business problems. Recognized as a top 5% performer for technical excellence, client leadership, and strategic innovation. Experienced in client-facing roles with demonstrated ability to translate technical solutions into business value.\n\nData Science & Analytics: Statistical modeling, time series analysis, experimental design, predictive analytics, machine learning, forecasting, data visualization\nData Engineering: Pipeline design and optimization, ETL/ELT processes, data architecture, cloud platforms (GCS & AWS), modern data stack (Polars, DuckDB, Dagster), database management\nTechnical Leadership: Full-stack data solutions, process automation, performance optimization, technical mentoring, modernization of legacy systems, cross-functional collaboration\nClient Engagement: Stakeholder management, technical communication, requirements gathering, solution design, project leadership, business development",
    "crumbs": [
      "resume"
    ]
  },
  {
    "objectID": "resume/index.html#experience",
    "href": "resume/index.html#experience",
    "title": "resume",
    "section": "Experience",
    "text": "Experience\n\nAdjunct Instructor\nWest Virginia University / Morgantown, WV / January 2025 - Present\nLectured & redesigned “IENG 331: Computer Applications in Industrial Engineering” curriculum, modernizing from traditional approach to practical data science and software engineering fundamentals covering Python, SQL, database management, and version control.\n\nCurriculum Development & Technical Education\n\nDeveloped comprehensive teaching materials incorporating industry-standard tools (DuckDB, Git, command line interfaces) to prepare students for modern data-driven roles.\nBridge academic theory with industry practice by teaching statistical concepts alongside practical implementation, emphasizing reproducible research and collaborative development practices.\n\n\n\n\nData Scientist\nOneMagnify / Remote, United States / January 2023 - Present\nFull-stack data scientist serving as data engineer, analyst, consultant, and client success lead across multiple high-impact engagements. Operate with complete autonomy managing technical relationships, project delivery, and strategic solution development for accounts generating $300K+ annual revenue.\n\nConsulting & Client Engagement\n\nLead technical relationship management as primary point of contact and solution architect for multiple high-value client accounts, consistently achieving 5-star ratings and strong retention. Independently manage client meetings, requirements gathering, and solution design while maintaining fully billable utilization generating approximately $25K monthly revenue.\nTransform complex business requirements into scalable technical solutions, serving simultaneously as project manager, technical lead, and client success representative. Navigate complex client dynamics and deliver solutions that consistently exceed expectations while building long-term strategic partnerships.\nDevelop and deliver custom analytical solutions tailored to specific client needs rather than generalized dashboards, specializing in converting manual processes into automated, repeatable systems that provide sustainable competitive advantages.\n\n\n\nProduct Leadership & Strategic Innovation\n\nConceptualized and serve as product lead for our Amazon Competitive Intelligence platform, independently designing scalable framework supporting clients with 400-5000+ SKUs. Generated significant internal interest and external traction, with solution presented to clients’ leadership and director-level stakeholders for potential enterprise deployment.\nBuilt proprietary machine learning sales estimation model using XGBoost to replace third-party dependencies, establishing foundation for new business opportunities while reducing operational costs and increasing data control. Created scalable repository architecture enabling rapid deployment across multiple client engagements.\nDeveloped comprehensive competitive marketplace reporting combining automated web scraping, real-time monitoring, and predictive analytics. Delivered integrated solutions tracking competitor performance, pricing dynamics, and market trends that directly influence strategic decisions and resource allocation.\n\n\n\nData Science & Analytics Innovation\n\nDesigned and implemented automated price optimization system incorporating competitive analysis, margin requirements, and marketplace dynamics for client’s 100+ Amazon ASINs. Created weekly recommendation models that enabled strategic pricing decisions leading to improved margins while maintaining competitive positioning.\nRedesigned legacy “Engagement Scoring” model serving 23 million customers across US and Canada, completely rebuilding statistical framework and migrating from outdated R/SAS system to modern Python architecture. Achieved 500% performance improvement while adding comprehensive data quality validation, logging, and error handling.\nDeveloped real-time BuyBox monitoring and competitive analysis systems processing millions of data points monthly, enabling clients to respond rapidly to competitive threats and identify pricing opportunities. Created automated reporting systems delivering actionable insights through both static analysis and and interactive dashboards.\n\n\n\nData Engineering & Technical Excellence\n\nArchitected modern data pipelines using medallion architecture principles, consolidating disparate data sources including SFTP, APIs, multiple databases across different VPNs, and cloud storage ito unified lakehouse structure for client engagements and internal projects. Improved data accessibility, processing speed, and system maintainability while reducing technical debt.\nEstablished comprehensive data engineering standards including Git version control, modern python environment management, automated testing, and reproducible workflows. Led team transition from R to Python ecosystem while maintaining operational continuity and elevating overall technical capabilities.\nOptimized critical data processing workflows by implementing modern DataFrame libraries (Polars) and analytical databases (DuckDB), achieving significant performance improvements while maintaining data quality and system reliability. Created internal Python packages enabling code reuse across multiple projects and team members.\n\n\n\n\nOperations Leadership Development Program\nXylem, Inc / Uniontown, PA & Morton Grove, IL / July 2021 - December 2022\nTwo-rotation leadership program providing comprehensive exposure to manufacturing operations, business analytics, and process improvement methodologies across multiple production facilities.\n\nRotation 2: Manufacturing Engineer\n\nLed comprehensive DMAIC project targeting excess and obsolete inventory reduction with projected hard savings of $1-4M over 3-5 years. developed data-driven classification methodology and cross-departmental disposition workflows that addressed both immediate warehouse constraints and long-term inventory optimization strategies.\nFacilitated organization-wide continuous improvement initiatives including Lean methodology workshops, 5S implementations, FMEA analyses, and statistical process capability studies. Drove cultural transformation towards operational excellence while establishing sustainable improvement processes across multiple manufacturing sites.\nApplied advanced statistical methods including control charts, process capability analysis, and value stream mapping to identify improvement opportunities and establish performance baselines for ongoing monitoring and optimization efforts.\n\n\n\nRotation 1: Business Data Analyst\n\nArchitected automated quarterly financial reporting system using SQL databases and advanced Excel automation techniques, achieving 90% process time reduction while ensuring audit compliance and standardization across three manufacturing sites. Created self-service reporting template enabling warehouse managers to maintain consistency without extensive training.\nRedesigned annual physical inventory cycle counting procedures through comprehensive process mapping and statistical sampling methodologies. Reduced event duration by one full workday at two sites while improving accuracy and reducing preparation time for management teams.\nDeveloped executive-level Tableau dashboards providing real-time visibility into quality metrics, forecasting accuracy, and operational performance indicators. Enabled data-driven decision making for Finance and Quality leadership while establishing sustainable reporting infrastructure for ongoing performance monitoring.\n\n\n\n\nUndergraduate Teaching Assistant\nWest Virginia University / Morgantown, WV / August 2019 - May 2021\nSupported instruction for four core courses.\n\nIENG 220: Re-engineering Management Systems\nIENG 305: Intro to Systems Engineering\nIENG 331: Computer Applications in Industrial Engineering\nIENG 445: Project Management for Engineers\n\n\n\nManufacturing Engineer Intern\nJLG Industries / McConnellsburg, PA / June 2019 - August 2019\n\nImplemented Lean Six Sigma improvements on critical production lines, developing standard work instructions and digital defect tracking systems that reduced variability and improved quality data collection.\nDesigned facility layouts using CAD software and statistical analysis, optimizing workflow efficiency and equipment utilization for tire installation processes.",
    "crumbs": [
      "resume"
    ]
  },
  {
    "objectID": "resume/index.html#education",
    "href": "resume/index.html#education",
    "title": "resume",
    "section": "Education",
    "text": "Education\n\nBachelor of Science, Industrial Engineering\nWest Virginia University / Morgantown, WV / August 2017 - May 2021\n\n\nProfessional Certifications\n\nLean Six Sigma Green Belt – Institute of Industrial and Systems Engineers\nContinuous Improvement Fundamentals – Oshkosh Corporation\nEligible for Certified Associate in Project Management (CAPM) – Project Management Institute",
    "crumbs": [
      "resume"
    ]
  },
  {
    "objectID": "projects/index.html",
    "href": "projects/index.html",
    "title": "projects",
    "section": "",
    "text": "Projects demonstrating my expertise across various data science technologies and methodologies.\n\n\n\n\nNo matching items",
    "crumbs": [
      "projects"
    ]
  },
  {
    "objectID": "projects/index.html#showcase",
    "href": "projects/index.html#showcase",
    "title": "projects",
    "section": "",
    "text": "Projects demonstrating my expertise across various data science technologies and methodologies.\n\n\n\n\nNo matching items",
    "crumbs": [
      "projects"
    ]
  },
  {
    "objectID": "projects/index.html#personal",
    "href": "projects/index.html#personal",
    "title": "projects",
    "section": "personal",
    "text": "personal\nCreative and self-driven projects I pursued for fun or personal growth.\n\n\n\n\nNo matching items",
    "crumbs": [
      "projects"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ozan Ozbeker",
    "section": "",
    "text": "Hey! I’m Ozan, a data scientist/engineer/detective with a background in industrial engineering. I currently work as a data analytics consultant at OneMagnify. Sometimes, I also teach at my alma mater, West Virginia University.\nOn this website, you’ll find my resume, projects, and blog, along with a teaching section covering courses I’ve taught (and hopefully some workshops & talks in the future). I’m also really interested in the tools others use, especially in the data realm. You can see mine at tech stack, and I’d love to learn about yours.\n\nThis website is still under development, but fully functional."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "blog",
    "section": "",
    "text": "Parameterized Emails with Quarto\n\n\n\nquarto\n\npython\n\nreporting\n\n\n\nSending static emails with reactive artifacts, powered by Quarto & Python.\n\n\n\n\n\nJul 5, 2025\n\n1 min\n\n\n\n\nNo matching items",
    "crumbs": [
      "blog"
    ]
  },
  {
    "objectID": "teaching/index.html",
    "href": "teaching/index.html",
    "title": "teaching",
    "section": "",
    "text": "Order By\n      Default\n      \n        Date - Oldest\n      \n      \n        Date - Newest\n      \n      \n        Title\n      \n    \n  \n\n\n\n\n\n\nDate\n\n\n\nTitle\n\n\n\nCategories\n\n\n\n\n\n\n\n\nJanuary 2025\n\n\nWVU GSCM 425\n\n\nOptimization, Python, Gurobi\n\n\n\n\n\n\nJanuary 2025\n\n\nWVU IENG 331\n\n\nData Analysis, Python, Polars, Plotly\n\n\n\n\n\n\nNo matching items",
    "crumbs": [
      "teaching"
    ]
  },
  {
    "objectID": "teaching/courses/2025-spring-wvu-gscm-425/index.html",
    "href": "teaching/courses/2025-spring-wvu-gscm-425/index.html",
    "title": "WVU GSCM 425",
    "section": "",
    "text": "This course offers a deep dive into supply chain network design, guiding students through the process of formulating real-world supply chain problems, gathering and validating data, and applying mathematical programming techniques to find optimal solutions. Students will develop basic yet practical Python programming skills to use Gurobi’s optimizer. Core topics include facility location, transportation and transshipment models, multi-objective and scenario-based optimization, and sensitivity analysis in the face of uncertainty. Emphasis is placed on the practical implementation of these tools and the communication of results in a managerial context."
  },
  {
    "objectID": "teaching/courses/2025-spring-wvu-gscm-425/index.html#course-description",
    "href": "teaching/courses/2025-spring-wvu-gscm-425/index.html#course-description",
    "title": "WVU GSCM 425",
    "section": "",
    "text": "This course offers a deep dive into supply chain network design, guiding students through the process of formulating real-world supply chain problems, gathering and validating data, and applying mathematical programming techniques to find optimal solutions. Students will develop basic yet practical Python programming skills to use Gurobi’s optimizer. Core topics include facility location, transportation and transshipment models, multi-objective and scenario-based optimization, and sensitivity analysis in the face of uncertainty. Emphasis is placed on the practical implementation of these tools and the communication of results in a managerial context."
  },
  {
    "objectID": "teaching/courses/2025-spring-wvu-gscm-425/index.html#learning-objectives",
    "href": "teaching/courses/2025-spring-wvu-gscm-425/index.html#learning-objectives",
    "title": "WVU GSCM 425",
    "section": "Learning Objectives",
    "text": "Learning Objectives\nUpon successful completion of this course, students will be able to:\n\nDemonstrate Fundamental Python Skills: Use Python effectively for data handling and basic scripting in preparation for optimization tasks.\nFormulate and Solve Supply Chain Network Problems: Model and solve facility location, transportation, and other network design challenges using both Gurobi and Excel Solver.\nEvaluate and Compare Optimization Tools: Interpret results produced by different solvers, comparing solution quality, run times, and applicability in real-world supply chain scenarios.\nCommunicate and Collaborate: Work in teams to analyze data, develop optimization models, and present solution insights and recommendations to stakeholders."
  }
]